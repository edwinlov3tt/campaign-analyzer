1. Adding more tactics and products for analysis • Use the information in @tactic-training/enhanced_tactic_categories.json and Output(13).json to map each detected tactic found in the response payload from the api call to its correct Product and Subproduct. Replace any incorrect labels (for example, remove "AAT"); keep "YouTube" unchanged where appropriate. • For each detected tactic, list Product and Subproduct in the tactics table upload. • Only show tables relevant to each detected tactic. Use @tactic-training/exportable-report-tables.txt to determine which tables are available for each tactic and allow users to upload those tables.
2. Tables & file uploads • Present the available uploadable csv tables for each tactic exactly as specified in @tactic-training/exportable-report-tables.txt. If a user uploads tables, verify they match the available list for that tactic, and include them in the output where relevant. • Allow the user to hide or minimize charts and tables in the final report if they request it.
3. Campaign timing awareness • Compute the current date/time relative to the campaign start and end dates included in the Lumina order. Use the system current timestamp (YYYY-MM-DD HH:MM in the user’s locale) to determine: – whether the campaign is ongoing, completed, or not yet started – whether the reporting period is partial (e.g., middle of a month) and explain how that may affect delivery or metrics • Always show the calculated “Report generation date and time” and the campaign start/end dates.
4. Metrics formatting rules • When reporting metric results, present single-value averages (not ranges). For example, convert "0.97–1.95 CTR" to the calculated average (e.g., "1.46% CTR avg"). Specify the sample or denominator used to compute the average if available. • Where appropriate, include day-over-day, week-over-week, or month-over-month comparisons versus previous periods and internal benchmarks if they are available.
5. Qualitative report tone & structure • , the AI output is pretty good, but incorporate some of the below traits to give even better output that sounds more than just "this is what you got" Use this 5-point output structure to help:
    1. High-level story of performance tied to goals (awareness, engagement, conversion). Note whether current timing affects delivery.
    2. Funnel-stage evaluation and what the tactic is optimized to do.
    3. Relative analysis — compare creatives, audiences, or past periods and state statistical confidence if sample sizes are small.
    4. Specific, actionable next steps for underperformers. Frame flaws as opportunities and give a concrete test or change to try.
    5. Summary of wins, risks, and recommended prioritization for the next period. Keep a positive, optimistic voice. • Tell a story across bullets: reference overall campaign goals and how each tactic contributes. • When sample sizes are small, explicitly call that out and recommend a larger window or different aggregation. • Keep language constructive: use “here’s how we’ll make it better” phrasing for critiques.
6. Modifiers & user controls • Add sections in the Modifers settings that will allow users to change: – Temperature: a numeric value to control creativity (e.g., 0.0–1.0). – Tone: choose from ['Concise', 'Professional', 'Conversational', 'Encouraging', 'Casual']. – Additional instructions: free-text box for any extra constraints or priorities. – Toggle: "Hide charts and tables" (minimize). • The assistant must honor these controls and adapt wording and creativity accordingly.
7. Charts, visuals, and tables • Include tables that map tactics to Product and Subproduct (from @tactic-training/). • When charts are present, include clear captions, date ranges, and whether the chart is partial (in-progress period). • Add a button to Hide charts and tables.
8. Keep a changelog note • Append a one-line changelog at the end of the report when the mapping or available tables changed from previous runs (if you can detect that).